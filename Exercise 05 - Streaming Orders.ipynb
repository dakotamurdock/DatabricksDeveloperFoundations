{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d4700c3-1343-4dcb-8df3-13eac52bc2e2"}}},{"cell_type":"markdown","source":["# Exercise #5 - Streaming Orders\n\nWith our four historical datasets properly loaded, we can now begin to process the \"current\" orders.\n\nIn this case, the new \"system\" is landing one JSON file per order into cloud storage.\n\nWe can process these JSON files as a stream of orders under the assumption that new orders are continually added to this dataset.\n\nIn order to keep this project simple, we have reduced the \"stream\" of orders to just the first few hours of 2020 and will be throttling that stream to only one file per iteration.\n\nThis exercise is broken up into 3 steps:\n* Exercise 5.A - Use Database\n* Exercise 5.B - Stream-Append Orders\n* Exercise 5.C - Stream-Append Line Items\n\n## Some Friendly Advice...\n\nEach record is a JSON object with roughly the following structure:\n\n* **`customerID`**\n* **`orderId`**\n* **`products`**\n  * array\n    * **`productId`**\n    * **`quantity`**\n    * **`soldPrice`**\n* **`salesRepId`**\n* **`shippingAddress`**\n  * **`address`**\n  * **`attention`**\n  * **`city`**\n  * **`state`**\n  * **`zip`**\n* **`submittedAt`**\n\nAs you ingest this data, it will need to be transformed to match the existing **`orders`** table's schema and the **`line_items`** table's schema.\n\nBefore attempting to ingest the data as a stream, we highly recomend that you start with a static **`DataFrame`** so that you can iron out the various kinks:\n* Renaming and flattening columns\n* Exploding the products array\n* Parsing the **`submittedAt`** column into a **`timestamp`**\n* Conforming to the **`orders`** and **`line_items`** schemas - because these are Delta tables, appending to them will fail if the schemas are not correct\n\nFurthermore, creating a stream from JSON files will first require you to specify the schema - you can \"cheat\" and infer that schema from some of the JSON files before starting the stream."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d79bfd83-2497-4da9-b434-a45b7f811b7b"}}},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Setup Exercise #5</h2>\n\nTo get started, we first need to configure your Registration ID and then run the setup notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a06d747-ad8d-49db-b049-370c0c768784"}}},{"cell_type":"markdown","source":["### Setup - Registration ID\n\nIn the next commmand, please update the variable **`registration_id`** with the Registration ID you received when you signed up for this project.\n\nFor more information, see [Registration ID]($./Registration ID)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d8b1a31-d55d-4399-aad5-da559c283342"}}},{"cell_type":"code","source":["registration_id = \"3339094\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fb27e64-21cb-4a50-96e2-22c3c5048e30"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Setup - Run the exercise setup\n\nRun the following cell to setup this exercise, declaring exercise-specific variables and functions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d21e0812-ab66-4f25-83bb-92d38710589a"}}},{"cell_type":"code","source":["%run ./_includes/Setup-Exercise-05"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9afd115e-c02a-4831-b594-c013abf03bff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<html><body><table style=\"width:100%\">\n            <p style=\"font-size:16px\">The following variables and functions have been defined for you.<br/>Please refer to them in the following instructions.</p><tr><th style=\"border-bottom:1px solid #CDCDCD; padding: 0 1em 0 0; text-align:left\">Variable/Function</th>\n                 <th style=\"border-bottom:1px solid #CDCDCD; padding: 0 1em 0 0; text-align:left\">Description</th></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">username</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dakota.murdock@wavicledata.com</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">This is the email address that you signed into Databricks with</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">working_dir</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">This is the directory in which all work should be conducted</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">user_db</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbacademy_dakota_murdock_wavicledata_com_developer_foundations_capstone</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the database you will use for this project.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">orders_table</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">orders</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the orders table.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">products_table</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">products</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the products table.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">line_items_table</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">line_items</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the line items table.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">stream_path</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone/raw/orders/stream</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The path to the stream directory of JSON orders</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">orders_checkpoint_path</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone/checkpoint/orders</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The location of the checkpoint for streamed orders</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">line_items_checkpoint_path</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone/checkpoint/line_items</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The location of the checkpoint for streamed line-items</td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_a()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating Exercise #5.A</td></td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_b()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating Exercise #5.B</td></td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_c()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating Exercise #5.C</td></td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_final()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating the entire exercise</td></td></tr></table></body></html>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<html><body><table style=\"width:100%\">\n            <p style=\"font-size:16px\">The following variables and functions have been defined for you.<br/>Please refer to them in the following instructions.</p><tr><th style=\"border-bottom:1px solid #CDCDCD; padding: 0 1em 0 0; text-align:left\">Variable/Function</th>\n                 <th style=\"border-bottom:1px solid #CDCDCD; padding: 0 1em 0 0; text-align:left\">Description</th></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">username</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dakota.murdock@wavicledata.com</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">This is the email address that you signed into Databricks with</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">working_dir</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">This is the directory in which all work should be conducted</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">user_db</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbacademy_dakota_murdock_wavicledata_com_developer_foundations_capstone</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the database you will use for this project.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">orders_table</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">orders</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the orders table.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">products_table</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">products</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the products table.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">line_items_table</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">line_items</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The name of the line items table.</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">stream_path</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone/raw/orders/stream</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The path to the stream directory of JSON orders</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">orders_checkpoint_path</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone/checkpoint/orders</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The location of the checkpoint for streamed orders</td></tr><tr><td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:green;\">line_items_checkpoint_path</td>\n                 <td style=\"font-size:16px; font-weight:bold; {padding} vertical-align:top; white-space:nowrap; color:blue;\">dbfs:/user/dakota.murdock@wavicledata.com/dbacademy/developer-foundations-capstone/checkpoint/line_items</td>\n             </tr><tr><td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding}\">&nbsp;</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD; font-size:16px; {padding} vertical-align:top;\">The location of the checkpoint for streamed line-items</td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_a()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating Exercise #5.A</td></td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_b()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating Exercise #5.B</td></td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_c()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating Exercise #5.C</td></td></tr><tr><td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top; font-weight:bold; white-space:nowrap; color:green;\">reality_check_05_final()</td>\n                 <td style=\"border-bottom:1px solid #CDCDCD;; font-size:16px; {padding} vertical-align:top;\">A utility function for validating the entire exercise</td></td></tr></table></body></html>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #5.A - Use Database</h2>\n\nEach notebook uses a different Spark session and will initially use the **`default`** database.\n\nAs in the previous exercise, we can avoid contention to commonly named tables by using our user-specific database.\n\n**In this step you will need to:**\n* Use the database identified by the variable **`user_db`** so that any tables created in this notebook are **NOT** added to the **`default`** database"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4426c9da-df9e-443f-96f3-ee13af4e5def"}}},{"cell_type":"markdown","source":["### Implement Exercise #5.A\n\nImplement your solution in the following cell:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81d46cad-1dd5-48a1-975a-bedc61666f1b"}}},{"cell_type":"code","source":["spark.sql(f\"USE {user_db};\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5b16866-6765-47a7-948e-ec61fe837bfa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: DataFrame[]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: DataFrame[]"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Reality Check #5.A\nRun the following command to ensure that you are on track:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e52c5f9-c281-4fe5-8e29-9bb3a65ee1c3"}}},{"cell_type":"code","source":["reality_check_05_a()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d47519b6-8c26-4a2c-beca-57cbe97d050e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Using DBR 9.1 & Proper Cluster Configuration\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Valid Registration ID\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    The current database is dbacademy_dakota_murdock_wavicledata_com_developer_foundations_capstone\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 195,698 orders\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 1,175,870 line-items\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 12 products\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 6</caption>\n</table>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Using DBR 9.1 & Proper Cluster Configuration\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Valid Registration ID\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    The current database is dbacademy_dakota_murdock_wavicledata_com_developer_foundations_capstone\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 195,698 orders\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 1,175,870 line-items\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 12 products\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 6</caption>\n</table>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #5.B - Stream-Append Orders</h2>\n\nEvery JSON file ingested by our stream representes one order and the enumerated list of products purchased in that order.\n\nOur goal is simple, ingest the data, transform it as required by the **`orders`** table's schema, and append these new records to our existing table.\n\n**In this step you will need to:**\n\n* Ingest the stream of JSON files:\n  * Start a stream from the path identified by **`stream_path`**.\n  * Using the **`maxFilesPerTrigger`** option, throttle the stream to process only one file per iteration.\n  * Add the ingest meta data (same as with our other datasets):\n    * **`ingested_at`**:**`timestamp`**\n    * **`ingest_file_name`**:**`string`**\n  * Properly parse the **`submitted_at`**  as a valid **`timestamp`**\n  * Add the column **`submitted_yyyy_mm`** usinge the format \"**yyyy-MM**\"\n  * Make any other changes required to the column names and data types so that they conform to the **`orders`** table's schema\n\n* Write the stream to a Delta **table**.:\n  * The table's format should be \"**delta**\"\n  * Partition the data by the column **`submitted_yyyy_mm`**\n  * Records must be appended to the table identified by the variable **`orders_table`**\n  * The query must be named the same as the table, identified by the variable **`orders_table`**\n  * The query must use the checkpoint location identified by the variable **`orders_checkpoint_path`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a173da7a-1e23-4fd6-a24b-52a22bf35c79"}}},{"cell_type":"markdown","source":["### Implement Exercise #5.B\n\nImplement your solution in the following cell:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4b88826-5150-469e-96df-d7f32720b4d4"}}},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\ndbutils.fs.rm(orders_checkpoint_path, True)\n\nschema = StructType(\n    [\n        StructField(\"customerId\",StringType(),True),\n        StructField(\"orderId\",StringType(),True),\n        StructField(\"products\",ArrayType(StructType([StructField(\"productId\",StringType(),True),\n                                                       StructField(\"quantity\",LongType(),True),\n                                                       StructField(\"soldPrice\",DoubleType(),True)]),True),True),\n        StructField(\"salesRepId\",StringType(),True),\n        StructField(\"shippingAddress\",StructType([StructField(\"address\",StringType(),True),\n                                                    StructField(\"attention\",StringType(),True),\n                                                    StructField(\"city\",StringType(),True),\n                                                    StructField(\"state\",StringType(),True),\n                                                    StructField(\"zip\",StringType(),True)]),True),\n        StructField(\"submittedAt\",StringType(),True)\n    ]\n)\n\ndf = (spark.readStream\n      .format(\"json\")\n      .option(\"maxFilesPerTrigger\", 1)\n      .schema(schema)\n      .load(stream_path)\n     )\n\ndf_orders = (df.select(\"submittedAt\", \"orderId\", \"customerId\", \"salesRepId\", \"shippingAddress\")\n              .withColumnRenamed(\"submittedAt\", \"submitted_at\")\n              .withColumnRenamed(\"orderId\", \"order_id\")\n              .withColumnRenamed(\"customerId\", \"customer_id\")\n              .withColumnRenamed(\"salesRepId\", \"sales_rep_id\")\n              .withColumnRenamed(\"shippingAddress\", \"shipping_address\")\n              .withColumn(\"ingest_file_name\", input_file_name())\n              .withColumn(\"submitted_at\", col(\"submitted_at\").cast(\"timestamp\")) # Convert from unix time and cast column to timestamp\n              .withColumn(\"submitted_yyyy_mm\", date_format(\"submitted_at\", \"yyyy-MM\")) # Created new year/month column from submitted_at column\n              .withColumn(\"ingested_at\", current_timestamp())\n              .withColumn(\"shipping_address_attention\", col(\"shipping_address\").attention)\n              .withColumn(\"shipping_address_address\", col(\"shipping_address\").address)\n              .withColumn(\"shipping_address_city\", col(\"shipping_address\").city)\n              .withColumn(\"shipping_address_state\", col(\"shipping_address\").state)\n              .withColumn(\"shipping_address_zip\", col(\"shipping_address\").zip.cast(\"integer\"))\n              .drop(\"shipping_address\")\n                    )\n\ndf_orders_query = (df_orders.writeStream\n                   .partitionBy(\"submitted_yyyy_mm\")\n                   .outputMode(\"append\")\n                   .format(\"delta\")\n                   .queryName(orders_table)\n                   .option(\"checkpointLocation\", orders_checkpoint_path)\n                   .table(orders_table)\n                  )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"131700a0-120d-489e-8843-6ee84a655241"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Reality Check #5.B\nRun the following command to ensure that you are on track.\n\n**Caution**: In the cell above, you will be appending to a Delta table and the final record count will be validated below. Should you restart the stream, you will inevitably append duplicate records to these tables forcing the validation to fail. There are two things you will need to address in this scenario:\n* Address the duplicate data issue by re-running **Exercise #3** which would presumably delete and/or overwrite the datasets, putting them back to their default state for this exercise.\n* Address the stream's state issue (remembering which files were processed) by deleting the directory identified by *`orders_checkpoint_path`*"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a974e741-09e9-410a-81a8-31a7e3a849b5"}}},{"cell_type":"code","source":["reality_check_05_b()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"524686e4-1c06-4ddc-aeb5-5567430caa65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The stream \"orders\" has started.\nThe stream hasn't processed any trigger yet...\nThe stream hasn't processed any trigger yet...\nThe stream has processed 1 triggers so far.\nProcessing trigger 2 of 20...\nProcessing trigger 3 of 20...\nProcessing trigger 4 of 20...\nProcessing trigger 4 of 20...\nProcessing trigger 5 of 20...\nProcessing trigger 6 of 20...\nProcessing trigger 7 of 20...\nProcessing trigger 8 of 20...\nProcessing trigger 9 of 20...\nProcessing trigger 9 of 20...\nProcessing trigger 10 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 12 of 20...\nProcessing trigger 13 of 20...\nProcessing trigger 13 of 20...\nProcessing trigger 14 of 20...\nProcessing trigger 15 of 20...\nProcessing trigger 16 of 20...\nProcessing trigger 16 of 20...\nProcessing trigger 17 of 20...\nProcessing trigger 18 of 20...\nProcessing trigger 19 of 20...\nProcessing trigger 19 of 20...\nProcessing trigger 20 of 20...\nProcessing results...\nPYTHON ERROR Invalid argument, not a string or column: 1636992285713.1057 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992285743.0703 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992286160.375 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992286217.0708 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992288169.8655 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992288187.5774 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nStopping the stream...\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The stream \"orders\" has started.\nThe stream hasn't processed any trigger yet...\nThe stream hasn't processed any trigger yet...\nThe stream has processed 1 triggers so far.\nProcessing trigger 2 of 20...\nProcessing trigger 3 of 20...\nProcessing trigger 4 of 20...\nProcessing trigger 4 of 20...\nProcessing trigger 5 of 20...\nProcessing trigger 6 of 20...\nProcessing trigger 7 of 20...\nProcessing trigger 8 of 20...\nProcessing trigger 9 of 20...\nProcessing trigger 9 of 20...\nProcessing trigger 10 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 12 of 20...\nProcessing trigger 13 of 20...\nProcessing trigger 13 of 20...\nProcessing trigger 14 of 20...\nProcessing trigger 15 of 20...\nProcessing trigger 16 of 20...\nProcessing trigger 16 of 20...\nProcessing trigger 17 of 20...\nProcessing trigger 18 of 20...\nProcessing trigger 19 of 20...\nProcessing trigger 19 of 20...\nProcessing trigger 20 of 20...\nProcessing results...\nPYTHON ERROR Invalid argument, not a string or column: 1636992285713.1057 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992285743.0703 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992286160.375 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992286217.0708 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992288169.8655 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992288187.5774 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nStopping the stream...\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected at least 20 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected less than 100 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected the first 20 triggers to processes 1 record per trigger\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Checkpoint directory exists\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 195,718 orders (20 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 5</caption>\n</table>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected at least 20 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected less than 100 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected the first 20 triggers to processes 1 record per trigger\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Checkpoint directory exists\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 195,718 orders (20 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 5</caption>\n</table>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #5.C - Stream-Append Line Items</h2>\n\nThe same JSON file we processed in the previous stream also contains the line items which we now need to extract and append to the existing **`line_items`** table.\n\nJust like before, our goal is simple, ingest the data, transform it as required by the **`line_items`** table's schema, and append these new records to our existing table.\n\nNote: we are processing the same stream twice - there are other patterns to do this more efficiently, but for this exercise, we want to keep the design simple.<br/>\nThe good news here is that you can copy most of the code from the previous step to get you started here.\n\n**In this step you will need to:**\n\n* Ingest the stream of JSON files:\n  * Start a stream from the path identified by **`stream_path`**.\n  * Using the **`maxFilesPerTrigger`** option, throttle the stream to process only one file per iteration.\n  * Add the ingest meta data (same as with our other datasets):\n    * **`ingested_at`**:**`timestamp`**\n    * **`ingest_file_name`**:**`string`**\n  * Make any other changes required to the column names and data types so that they conform to the **`line_items`** table's schema\n    * The most significant transformation will be to the **`products`** column.\n    * The **`products`** column is an array of elements and needs to be exploded (see **`pyspark.sql.functions`**)\n    * One solution would include:\n      1. Select **`order_id`** and explode **`products`** while renaming it to **`product`**.\n      2. Flatten the **`product`** column's nested values.\n      3. Add the ingest meta data (**`ingest_file_name`** and **`ingested_at`**).\n      4. Convert data types as required by the **`line_items`** table's schema.\n\n* Write the stream to a Delta sink:\n  * The sink's format should be \"**delta**\"\n  * Records must be appended to the table identified by the variable **`line_items_table`**\n  * The query must be named the same as the table, identified by the variable **`line_items_table`**\n  * The query must use the checkpoint location identified by the variable **`line_items_checkpoint_path`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8419c43a-0311-460b-bfdf-d94492994785"}}},{"cell_type":"markdown","source":["### Implement Exercise #5.C\n\nImplement your solution in the following cell:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca818a7b-7a3a-495e-9517-2a0593c6a14c"}}},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\ndbutils.fs.rm(line_items_checkpoint_path, True)\n\nschema = StructType(\n    [\n        StructField(\"customerId\",StringType(),True),\n        StructField(\"orderId\",StringType(),True),\n        StructField(\"products\",ArrayType(StructType([StructField(\"productId\",StringType(),True),\n                                                       StructField(\"quantity\",LongType(),True),\n                                                       StructField(\"soldPrice\",DoubleType(),True)]),True),True),\n        StructField(\"salesRepId\",StringType(),True),\n        StructField(\"shippingAddress\",StructType([StructField(\"address\",StringType(),True),\n                                                    StructField(\"attention\",StringType(),True),\n                                                    StructField(\"city\",StringType(),True),\n                                                    StructField(\"state\",StringType(),True),\n                                                    StructField(\"zip\",StringType(),True)]),True),\n        StructField(\"submittedAt\",StringType(),True)\n    ]\n)\n\ndf = (spark.readStream\n      .format(\"json\")\n      .option(\"maxFilesPerTrigger\", 1)\n      .schema(schema)\n      .load(stream_path)\n     )\n\ndf_line_item = (df.select(\"orderId\", \"products\")\n              .withColumnRenamed(\"orderId\", \"order_id\")\n              .withColumn(\"product\", explode(\"products\"))\n              .withColumn(\"product_id\", col(\"product\").productId.cast(\"String\"))\n              .withColumn(\"product_quantity\", col(\"product\").quantity.cast(\"Integer\"))\n              .withColumn(\"product_sold_price\", col(\"product\").soldPrice.cast(DecimalType(10, 2)))\n              .withColumn(\"ingest_file_name\", input_file_name())\n              .withColumn(\"ingested_at\", current_timestamp())\n              .drop(\"products\")\n              .drop(\"product\")\n                    )\n\ndf_line_item_query = (df_line_item.writeStream\n                   .outputMode(\"append\")\n                   .format(\"delta\")\n                   .queryName(line_items_table)\n                   .option(\"checkpointLocation\", line_items_checkpoint_path)\n                   .table(line_items_table)\n                  )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0421c73c-8646-427d-b35e-b9bb3fc302fe"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["reality_check_05_c()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59f1c73e-dbc9-4514-87f4-3d2a925abac0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The stream \"line_items\" has started.\nThe stream hasn't processed any trigger yet...\nThe stream hasn't processed any trigger yet...\nThe stream has processed 1 triggers so far.\nProcessing trigger 2 of 20...\nProcessing trigger 3 of 20...\nProcessing trigger 4 of 20...\nProcessing trigger 5 of 20...\nProcessing trigger 6 of 20...\nProcessing trigger 7 of 20...\nProcessing trigger 8 of 20...\nProcessing trigger 9 of 20...\nProcessing trigger 10 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 12 of 20...\nProcessing trigger 13 of 20...\nProcessing trigger 14 of 20...\nProcessing trigger 15 of 20...\nProcessing trigger 16 of 20...\nProcessing trigger 17 of 20...\nProcessing trigger 18 of 20...\nProcessing trigger 18 of 20...\nProcessing trigger 19 of 20...\nProcessing trigger 20 of 20...\nProcessing results...\nPYTHON ERROR Invalid argument, not a string or column: 1636992409637.249 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992409689.4202 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992410101.8313 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992410150.453 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992411794.128 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992411818.012 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nStopping the stream...\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The stream \"line_items\" has started.\nThe stream hasn't processed any trigger yet...\nThe stream hasn't processed any trigger yet...\nThe stream has processed 1 triggers so far.\nProcessing trigger 2 of 20...\nProcessing trigger 3 of 20...\nProcessing trigger 4 of 20...\nProcessing trigger 5 of 20...\nProcessing trigger 6 of 20...\nProcessing trigger 7 of 20...\nProcessing trigger 8 of 20...\nProcessing trigger 9 of 20...\nProcessing trigger 10 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 11 of 20...\nProcessing trigger 12 of 20...\nProcessing trigger 13 of 20...\nProcessing trigger 14 of 20...\nProcessing trigger 15 of 20...\nProcessing trigger 16 of 20...\nProcessing trigger 17 of 20...\nProcessing trigger 18 of 20...\nProcessing trigger 18 of 20...\nProcessing trigger 19 of 20...\nProcessing trigger 20 of 20...\nProcessing results...\nPYTHON ERROR Invalid argument, not a string or column: 1636992409637.249 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992409689.4202 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992410101.8313 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992410150.453 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992411794.128 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992411818.012 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nStopping the stream...\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected at least 20 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected less than 100 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected the first 20 triggers to processes 1 record per trigger\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Checkpoint directory exists\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 1,175,967 records, (97 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 5</caption>\n</table>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected at least 20 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected less than 100 triggers\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected the first 20 triggers to processes 1 record per trigger\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Checkpoint directory exists\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 1,175,967 records, (97 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 5</caption>\n</table>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #5 - Final Check</h2>\n\nRun the following command to make sure this exercise is complete:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a2c7175-1a6e-44c1-b477-0ca439ec325b"}}},{"cell_type":"code","source":["reality_check_05_final()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eca36c24-d152-4770-a704-8541f66daf2a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"PYTHON ERROR Invalid argument, not a string or column: 1636992414132.0525 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992414149.7625 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992414163.6792 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992415087.5708 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992415711.6975 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992416348.2397 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992444513.8699 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992444533.332 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992444547.5107 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["PYTHON ERROR Invalid argument, not a string or column: 1636992414132.0525 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992414149.7625 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992414163.6792 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992415087.5708 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992415711.6975 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992416348.2397 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992444513.8699 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992444533.332 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\nPYTHON ERROR Invalid argument, not a string or column: 1636992444547.5107 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Reality Check 05.A passed\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Reality Check 05.B passed\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Reality Check 05.C passed\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 195,718 orders (20 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 1,175,967 records, (97 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 12 products\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Non-null (properly parsed) submitted_at\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 7</caption>\n</table>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style>\n  table { text-align: left; border-collapse: collapse; margin: 1em; caption-side: bottom; font-family: Sans-Serif; font-size: 16px}\n  caption { text-align: left; padding: 5px }\n  th, td { border: 1px solid #ddd; padding: 5px }\n  th { background-color: #ddd }\n  .passed { background-color: #97d897 }\n  .failed { background-color: #e2716c }\n  .skipped { background-color: #f9d275 }\n  .results .points { display: none }\n  .results .message { display: block; font-size:smaller; color:gray }\n  .results .note { display: block; font-size:smaller; font-decoration:italics }\n  .results .passed::before  { content: \"Passed\" }\n  .results .failed::before  { content: \"Failed\" }\n  .results .skipped::before { content: \"Skipped\" }\n  .grade .passed  .message:empty::before { content:\"Passed\" }\n  .grade .failed  .message:empty::before { content:\"Failed\" }\n  .grade .skipped .message:empty::before { content:\"Skipped\" }\n</style>\n<table class='results'>\n  <tr><th class='points'>Points</th><th class='test'>Test</th><th class='result'>Result</th></tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Reality Check 05.A passed\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Reality Check 05.B passed\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Reality Check 05.C passed\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 195,718 orders (20 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 1,175,967 records, (97 new)\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Expected 12 products\n  </td>\n  <td class='result passed'></td>\n</tr>\n<tr>\n  <td class='points'>1</td>\n  <td class='test'>\n    Non-null (properly parsed) submitted_at\n  </td>\n  <td class='result passed'></td>\n</tr>\n  <caption class='points'>Score: 7</caption>\n</table>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2021 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13a6d334-6ffb-4cdf-89e3-9a53f097bccc"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Exercise 05 - Streaming Orders","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1058723392004751}},"nbformat":4,"nbformat_minor":0}
